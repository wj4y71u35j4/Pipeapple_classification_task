# Pipeapple classification task
## Introduction
在近年來，影像辨識技術已成為人工智慧領域的熱門研究領域之一。透過將圖像轉換為數字資料，影像辨識技術可以自動識別、分類和標註圖像內容。在農業領域中，影像辨識技術也可以應用於農作物的自動檢測、分類和標註。

本研究旨在探討使用影像辨識技術識別鳳梨生長階段的可行性和效率。架構上，我使用了 EfficientNet 作為 CNN 架構，並透過郭老師提供了九種不同生長階段的鳳梨影像，每種不同生長階段分別有200張影像，共1800張影像以供訓練。我首先先將資料分成訓練集和驗證集，並在訓練集上使用資料增強方法，並且訓練時確保每個Class的資料筆數相同。除此之外，我還使用了 ＡdamW優化器和早期停止技術(early stop)來避免模型過度擬合。實驗結果顯示，使用這些技術可以使模型在驗證集上達到 95% 以上的準確率，並在最後以LIME (Local Interpretable Model-agnostic Explanations) 解釋模型方法，分析圖片中重要的像素點，並以視覺化的形式標示出來。

在本研究中，我將詳細介紹我所使用的方法，並提供實驗結果以證明這些方法的有效性。希望能夠為未來使用影像辨識技術識別鳳梨生長階段提供有價值的參考。

## Methodology
在本研究中，使用的數據集是由郭教授提供的鳳梨生長階段影像，其中包含了九種不同的生長階段，每種生長階段裡均有 200 張圖片。這些圖片已經過專家人工標註，以確保分類的準確性。

架構上，我使用了 EfficientNet 作為 CNN 架構，因為它在多個圖像辨識基准測試中表現出色(參照下圖)，並且相對於其他架構而言具有更少的參數數量，因此可以訓練得更快。

![effnet_moment](https://user-images.githubusercontent.com/81171903/230871804-19ba063a-8941-4788-9233-213899e526a6.png)

在本研究中我分別使用了b0級別和b3級別的EfficientNet作訓練，以下結果分別比較了在同樣超參數條件下，僅改變model架構後，因有early stopping機制的前提下，b0模型的loss curve收斂效果更好。

![effnet_moment](https://user-images.githubusercontent.com/81171903/230872724-4038a21b-5862-4a7a-917c-925757f6c128.png)

 在損失函數的選擇上，我這邊是以 CrossEntropy 作為損失函數，因為它可以有效的符合多目標分類問題，並懲罰分類錯誤。而在優化器上，我使用了 AdamW作為我們的優化器，因為它不但有Adam能夠快速收斂並且有較低的計算複雜度的特色外，也在該基礎上加上Weight Decay(也稱L2正則化)，可以有效的降低模型複雜度，並避免overfitting。以下為在相同超參數(皆為b0模型)前提下，Weight Decay 0.0001和0.02的比較結果。
 
 可以發現使用Weight Decay=0.02(如右圖)所執行的iteration僅只需35次即可完成收斂，而低Weight Decay的代價(如左圖)就是更長的收斂時間，與右邊相比多了兩倍時間完成收斂。
 
 ![effnet_moment](https://user-images.githubusercontent.com/81171903/230872974-141f7ebd-eab6-49b1-bbbf-2f2ce6b6dbea.png)

本研究中，我有使用資料增強方法來增加訓練資料量，並提高模型的泛化能力。我們使用的資料增強方法包括隨機水平翻轉、隨機垂直翻轉、隨機旋轉 45 度以及調整亮度、對比度、飽和度和色調等。下面兩張圖是比較使用資料增強後的訓練集影像，和未使用資料增強方式的驗證集影像。

訓練方式為將資料以8:2的比例區分訓練集和驗證集，並在50%的訓練集資料使用資料增強方式，以提高模型泛化能力。

![effnet_moment](https://user-images.githubusercontent.com/81171903/230873108-1cf66e17-7e72-4eb6-8ec9-162d65e6b278.png)

 Early stop的邏輯為，若驗證集之後三次epoch所平均出來的loss值，比最低的一次loss值還高的話，及停止訓練以防止overfitting。
 
 Class Stratification則是在訓練和驗證資料時，確保每個不同生長階段的資料有相同筆數的輸入，以防止訓練時可能太過集中訓練某一生長階段的結果。
 
 ## Result
 
 經過眾多實驗結果，我以EfficientNet-b0作為訓練架構，並將Weight Decay調整為0.001以防止loss curve劇烈波動的問題發生，以下為Accuracy curve和Loss Curve。
 
 ![effnet_moment](https://user-images.githubusercontent.com/81171903/230873312-3f05203d-df36-47be-bac1-5dad5f83e614.png)

以下為Confusion Matrix，驗證集中每個class各有40筆影像，可看出錯誤幾乎集中在最後兩個生長階段701和705，除此之外的生長階段幾乎都能正確識別。

![effnet_moment](https://user-images.githubusercontent.com/81171903/230873417-5e1f6ec6-ae0c-4b03-a213-83fc65474b05.png)

以下為我利用LIME可解釋模型，視覺化重要像素點的分布，可看出501生長階段模型傾向辨識葉子，而隨著鳳梨長大，逐漸將辨識重心移到鳳梨本身以及周遭的枝葉上。

![effnet_moment](https://user-images.githubusercontent.com/81171903/230873579-edaafdd8-ec24-4463-bf65-0fa10b835896.png)

## Discuss
在本研究中，我利用了 EfficientNet、AdamW、資料增強以及早期停止技術，達到了在驗證集上 95% 的準確率。相信這足以證明本研究使用的模型辨識鳳梨生長階段有一些成效。

此外，該模型也顯示出良好的泛化能力。透過使用資料增強和 AdamW優化器，我們能夠有效地減少overfitting的情況，並提升模型對新數據的適應能力。

在未來的研究中，可以考慮將本方法應用於其他領域，例如醫學影像辨識或植物生長監測。我們也可以嘗試不同方法，例如使用更複雜的 CNN 架構或使用不同的正規化方法，以解決更複雜的問題，當然，在本次實驗中，因為使用的dataset並不算大，故網路的深度並沒有直接反映在準確率上。

故我認為在未來的研究也可以考慮使用更大的數據集進行實驗，例如提高生長辨識階段的數目，以更加精確地評斷本方法的效果。除此之外，也可以嘗試優化本實驗的方法，例如通過調整超參數或使用不同的學習率调度策略來提高模型的性能。

透過繼續探究這些方向，希望能為辨識鳳梨生長階段和其他相關問題帶來貢獻。
